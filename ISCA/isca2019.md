### isca 2019 | 62 papers.
---
### Perceptron-based prefetch filtering.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322207
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322207?download=true
* **Key Words**: 
* **Abstract**: Hardware prefetching is an effective technique for hiding cache miss latencies in modern processor designs. Prefetcher performance can be characterized by two main metrics that are generally at odds with one another: coverage, the fraction of baseline cache misses which the prefetcher brings into the cache; and accuracy, the fraction of prefetches which are ultimately used. An overly aggressive prefetcher may improve coverage at the cost of reduced accuracy. Thus, performance may be harmed by this over-aggressiveness because many resources are wasted, including cache capacity and bandwidth. An ideal prefetcher would have both high coverage and accuracy.

---
### Post-silicon CPU adaptation made practical using machine learning.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322267
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322267?download=true
* **Key Words**: Computer systems organization Architectures Serial architectures Superscalar architectures Computing methodologies Artificial intelligence Control methods Computational control theory Machine learning Learning settings Batch learning 
* **Abstract**: Processors that adapt architecture to workloads at runtime promise compelling performance per watt (PPW) gains, offering one way to mitigate diminishing returns from pipeline scaling. State-of-the-art adaptive CPUs deploy machine learning (ML) models on-chip to optimize hardware by recognizing workload patterns in event counter data. However, despite breakthrough PPW gains, such designs are not yet widely adopted due to the potential for systematic adaptation errors in the field.

---
### Bit-level perceptron prediction for indirect branches.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322217
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322217?download=true
* **Key Words**: 
* **Abstract**: Modern software uses indirect branches for various purposes including, but not limited to, virtual method dispatch and implementation of switch statements. Because an indirect branch's target address cannot be determined prior to execution, high-performance processors depend on highly-accurate indirect branch prediction techniques to mitigate control hazards.

---
### Generative and multi-phase learning for computer systems optimization.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3326633
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3326633?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Heterogeneous (hybrid) systems Embedded and cyber-physical systems Embedded systems Real-time systems Real-time system architecture Computing methodologies Machine learning Hardware Power and energy Power estimation and optimization Chip-level power issues 
* **Abstract**: Machine learning and artificial intelligence are invaluable for computer systems optimization: as computer systems expose more resources for management, ML/AI is necessary for modeling these resources' complex interactions. The standard way to incorporate ML/AI into a computer system is to first train a learner to accurately predict the system's behavior as a function of resource usage---e.g., to predict energy efficiency as a function of core usage---and then deploy the learned model as part of a system---e.g., a scheduler. In this paper, we show that (1) continued improvement of learning accuracy may not improve the systems result, but (2) incorporating knowledge of the systems problem into the learning process improves the systems results even though it may not improve overall accuracy. Specifically, we learn application performance and power as a function of resource usage with the systems goal of meeting latency constraints with minimal energy. We propose a novel generative model which improves learning accuracy given scarce data, and we propose a multi-phase sampling technique, which incorporates knowledge of the systems problem. Our results are both positive and negative. The generative model improves accuracy, even for state-of-the-art learning systems, but negatively impacts energy. Multi-phase sampling reduces energy consumption compared to the state-of-the-art, but does not improve accuracy. These results imply that learning for systems optimization may have reached a point of diminishing returns where accuracy improvements have little effect on the systems outcome. Thus we advocate that future work on learning for systems should de-emphasize accuracy and instead incorporate the system problem's structure into the learner.

---
### OO-VR: NUMA friendly object-oriented VR rendering framework for future NUMA-based multi-GPU systems.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322247
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322247?download=true
* **Key Words**: 
* **Abstract**: With the strong computation capability, NUMA-based multi-GPU system is a promising candidate to provide sustainable and scalable performance for Virtual Reality (VR) applications and deliver the excellent user experience. However, the entire multi-GPU system is viewed as a single GPU under the single programming model which greatly ignores the data locality among VR rendering tasks during the workload distribution, leading to tremendous remote memory accesses among GPU models (GPMs). The limited inter-GPM link bandwidth (e.g., 64GB/s for NVlink) becomes the major obstacle when executing VR applications in the multi-GPU system. By conducting comprehensive characterizations on different kinds of parallel rendering frameworks, we observe that distributing the rendering object along with its required data per GPM can reduce the inter-GPM memory accesses. However, this object-level rendering still faces two major challenges in NUMA-based multi-GPU system: (1) the large data locality between the left and right views of the same object and the data sharing among different objects and (2) the unbalanced workloads induced by the software-level distribution and composition mechanisms.

---
### PES: proactive event scheduling for responsive and energy-efficient mobile web computing.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322248
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322248?download=true
* **Key Words**: General and reference Cross-computing tools and techniques Performance 
* **Abstract**: Web applications are gradually shifting toward resource-constrained mobile devices. As a result, the Web runtime system must simultaneously address two challenges: responsiveness and energy-efficiency. Conventional Web runtime systems fall short due to their reactive nature: they react to a user event only after it is triggered. The reactive strategy leads to local optimizations that schedule event executions one at a time, missing global optimization opportunities.

---
### 3D-based video recognition acceleration by leveraging temporal locality.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322260
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322260?download=true
* **Key Words**: 
* **Abstract**: Recent years have seen an explosion of domain-specific accelerator for Convolutional Neural Networks (CNN). Most of the prior CNN accelerators target neural networks on image recognition, such as AlexNet, VGG, GoogleNet, ResNet, etc. In this paper, we take a different route and study the acceleration of 3D CNN, which are more computational-intensive than 2D CNN and exhibits more opportunities. After our characterization on representative 3D CNNs, we leverage differential convolution across the temporal dimension, which operates on the temporal delta of imaps for each layer and process the computation bit-serially using only the effectual bits of the temporal delta. To further leverage the spatial locality and temporal locality, and make the architecture general to all CNNs, we propose a control mechanism to dynamically switch across spatial delta dataflow and temporal delta dataflow. We call our design temporal-spatial value aware accelerator (TSVA). Evaluation on a set of representation NN networks shows that TSVA can achieve an average of 4.24× speedup and 1.42× energy efficiency. While we target 3D CNN for video recognition, TSVA could also benefit other general CNNs for continuous batch processing.

---
### Energy-efficient video processing for virtual reality.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322264
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322264?download=true
* **Key Words**: Hardware Emerging technologies Analysis and design of emerging devices and systems Emerging architectures Integrated circuits Reconfigurable logic and FPGAs Hardware accelerators Power and energy Power estimation and optimization Platform power issues 
* **Abstract**: Virtual reality (VR) has huge potential to enable radically new applications, behind which spherical panoramic video processing is one of the backbone techniques. However, current VR systems reuse the techniques designed for processing conventional planar videos, resulting in significant energy inefficiencies. Our characterizations show that operations that are unique to processing 360° VR content constitute 40% of the total processing energy consumption.

---
### Triad-NVM: persistency for integrity-protected and encrypted non-volatile memories.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322250
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322250?download=true
* **Key Words**: Computer systems organization Architectures Hardware Emerging technologies Security and privacy Cryptography Database and storage security Systems security 
* **Abstract**: Non-Volatile Memory is here and provides an attractive fabric for main memory. Unlike DRAM, non-volatile main memory (NVMM) retains data after power loss. This allows memory to host data persistently across crashes and reboots, but opens up opportunities for attackers to snoop and/or tamper with data between boot episodes. While memory encryption and integrity verification have been well studied for DRAM systems, new challenges surface for NVMM if we want to simultaneously preserve security guarantees, data recovery across crashes/reboots, good persistence performance, and fast recovery.

---
### GraphSSD: graph semantics aware SSD.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322275
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322275?download=true
* **Key Words**: Hardware Communication hardware, interfaces and storage External storage 
* **Abstract**: Graph analytics play a key role in a number of applications such as social networks, drug discovery, and recommendation systems. Given the large size of graphs that may exceed the capacity of the main memory, application performance is bounded by storage access time. Out-of-core graph processing frameworks try to tackle this storage access bottleneck through techniques such as graph sharding, and sub-graph partitioning. Even with these techniques, the need to access data across different graph shards or sub-graphs causes storage systems to become a significant performance hurdle. In this paper, we propose a graph semantic aware solid state drive (SSD) framework, called GraphSSD, which is a full system solution for storing, accessing, and performing graph analytics on SSDs. Rather than treating storage as a collection of blocks, GraphSSD considers graph structure while deciding on graph layout, access, and update mechanisms. GraphSSD replaces the conventional logical to physical page mapping mechanism in an SSD with a novel vertex-to-page mapping scheme and exploits the detailed knowledge of the flash properties to minimize page accesses. GraphSSD also supports efficient graph updates (vertex and edge modifications) by minimizing unnecessary page movement overheads. GraphSSD provides a simple programming interface that enables application developers to access graphs as native data in their applications, thereby simplifying the code development. It also augments the NVMe (non-volatile memory express) interface with a minimal set of changes to map the graph access APIs to appropriate storage access mechanisms.

---
### CROW: a low-cost substrate for improving DRAM performance, energy efficiency, and reliability.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322231
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322231?download=true
* **Key Words**: Hardware Integrated circuits Semiconductor memory Dynamic memory 
* **Abstract**: DRAM has been the dominant technology for architecting main memory for decades. Recent trends in multi-core system design and large-dataset applications have amplified the role of DRAM as a critical system bottleneck. We propose Copy-Row DRAM (CROW), a flexible substrate that enables new mechanisms for improving DRAM performance, energy efficiency, and reliability. We use the CROW substrate to implement 1) a low-cost in-DRAM caching mechanism that lowers DRAM activation latency to frequently-accessed rows by 38% and 2) a mechanism that avoids the use of short-retention-time rows to mitigate the performance and energy overhead of DRAM refresh operations. CROW's flexibility allows the implementation of both mechanisms at the same time. Our evaluations show that the two mechanisms synergistically improve system performance by 20.0% and reduce DRAM energy by 22.3% for memory-intensive four-core workloads, while incurring 0.48% extra area overhead in the DRAM chip and 11.3 KiB storage overhead in the memory controller, and consuming 1.6% of DRAM storage capacity, for one particular implementation.

---
### Janus: optimizing memory and storage support for non-volatile memory systems.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322206
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322206?download=true
* **Key Words**: Computer systems organization Dependable and fault-tolerant systems and networks Processors and memory architectures Hardware Emerging technologies Memory and dense storage 
* **Abstract**: Non-volatile memory (NVM) technologies can manipulate persistent data directly in memory. Ensuring crash consistency of persistent data enforces that data updates reach all the way to NVM, which puts these write requests on the critical path. Recent literature sought to reduce this performance impact. However, prior works have not fully accounted for all the backend memory operations (BMOs) performed at the memory controller that are necessary to maintain persistent data in NVM. These BMOs include support for encryption, integrity protection, compression, deduplication, etc., necessary to provide security, endurance, and lifetime guarantees. These BMOs significantly increase the NVM write latency and exacerbate the performance degradation caused by the critical write requests. The goal of this work is to minimize the BMO overhead of write requests in an NVM system.

---
### Anubis: ultra-low overhead and recovery time for secure non-volatile memories.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322252
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322252?download=true
* **Key Words**: Computer systems organization Architectures Hardware Emerging technologies Security and privacy Cryptography Database and storage security Systems security 
* **Abstract**: Implementing secure Non-Volatile Memories (NVMs) is challenging, mainly due to the necessity to persist security metadata along with data. Unlike conventional secure memories, NVM-equipped systems are expected to recover data after crashes and hence security metadata must be recoverable as well. While prior work explored recovery of encryption counters, fewer efforts have been focused on recovering integrity-protected systems. In particular, how to recover Merkle Tree. We observe two major challenges for this. First, recovering parallelizable integrity trees, e.g., Intel's SGX trees, requires very special handling due to inter-level dependency. Second, the recovery time of practical NVM sizes (terabytes are expected) would take hours. Most data centers, cloud systems, intermittent-power devices and even personal computers, are anticipated to recover almost instantly after power restoration. In fact, this is one of the major promises of NVMs.

---
### Emerald: graphics modeling for SoC systems.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322221
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322221?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Heterogeneous (hybrid) systems Embedded and cyber-physical systems System on a chip Computing methodologies Computer graphics Graphics systems and interfaces Graphics processors Modeling and simulation 
* **Abstract**: Mobile systems-on-chips (SoCs) have become ubiquitous computing platforms, and, in recent years, they have become increasingly heterogeneous and complex. A typical SoC includes CPUs, graphics processor units (GPUs), image processors, video encoders/decoders, AI engines, digital signal processors (DSPs) and 2D engines among others [33, 70, 71]. One of the most significant SoC units in terms of both off-chip memory bandwidth and SoC die area is the GPU. In this paper, we present Emerald, a simulator that builds on existing tools to provide a unified model for graphics and GPGPU applications. Emerald enables OpenGL (v4.5) and OpenGL ES (v3.2) shaders to run on GPGPU-Sim's timing model and is integrated with gem5 and Android to simulate full SoCs. Emerald thus provides a platform for studying system-level SoC interactions while including the impact of graphics.

---
### Linebacker: preserving victim cache lines in idle register files of GPUs.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322222
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322222?download=true
* **Key Words**: Computer systems organization Dependable and fault-tolerant systems and networks General and reference Cross-computing tools and techniques Performance Networks Network performance evaluation Social and professional topics Professional topics Computing profession Testing, certification and licensing 
* **Abstract**: Modern GPUs suffer from cache contention due to the limited cache size that is shared across tens of concurrently running warps. To increase the per-warp cache size prior techniques proposed warp throttling which limits the number of active warps. Warp throttling leaves several registers to be dynamically unused whenever a warp is throttled. Given the stringent cache size limitation in GPUs this work proposes a new cache management technique named Linebacker (LB) that improves GPU performance by utilizing idle register file space as victim cache space. Whenever a CTA becomes inactive, linebacker backs up the registers of the throttled CTA to the off-chip memory. Then, linebacker utilizes the corresponding register file space as victim cache space. If any load instruction finds data in the victim cache line, the data is directly copied to the destination register through a simple register-register move operation. To further improve the efficiency of victim cache linebacker allocates victim cache space only to a select few load instructions that exhibit high data locality. Through a careful design of victim cache indexing and management scheme linebacker provides 29.0% of speedup compared to the previously proposed warp throttling techniques.

---
### MGPUSim: enabling multi-GPU performance modeling and optimization.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322230
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322230?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Single instruction, multiple data Computing methodologies Modeling and simulation Simulation support systems Simulation tools 
* **Abstract**: The rapidly growing popularity and scale of data-parallel workloads demand a corresponding increase in raw computational power of Graphics Processing Units (GPUs). As single-GPU platforms struggle to satisfy these performance demands, multi-GPU platforms have started to dominate the high-performance computing world. The advent of such systems raises a number of design challenges, including the GPU microarchitecture, multi-GPU interconnect fabric, runtime libraries, and associated programming models. The research community currently lacks a publicly available and comprehensive multi-GPU simulation framework to evaluate next-generation multi-GPU system designs.

---
### Opportunistic computing in GPU architectures.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322212
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322212?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Interconnection architectures Single instruction, multiple data Networks Network types Network on chip 
* **Abstract**: Data transfer overhead between computing cores and memory hierarchy has been a persistent issue for von Neumann architectures and the problem has only become more challenging with the emergence of manycore systems. A conceptually powerful approach to mitigate this overhead is to bring the computation closer to data, known as Near Data Computing (NDC). Recently, NDC has been investigated in different flavors for CPU-based multicores, while the GPU domain has received little attention. In this paper, we present a novel NDC solution for GPU architectures with the objective of minimizing on-chip data transfer between the computing cores and Last-Level Cache (LLC). To achieve this, we first identify frequently occurring Load-Compute-Store instruction chains in GPU applications. These chains, when offloaded to a compute unit closer to where the data resides, can significantly reduce data movement. We develop two offloading techniques, called LLC-Compute and Omni-Compute. The first technique, LLC-Compute, augments the LLCs with computational hardware for handling the computation offloaded to them. The second technique (Omni-Compute) employs simple bookkeeping hardware to enable GPU cores to compute instructions offloaded by other GPU cores. Our experimental evaluations on nine GPGPU workloads indicate that the LLC-Compute technique provides, on an average, 19% performance improvement (IPC), 11% performance/watt improvement, and 29% reduction in on-chip data movement compared to the baseline GPU design. The Omni-Compute design boosts these benefits to 31%, 16% and 44%, respectively.

---
### Interplay between hardware prefetcher and page eviction policy in CPU-GPU unified virtual memory.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322224
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322224?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Heterogeneous (hybrid) systems Parallel architectures Single instruction, multiple data Computing methodologies Computer graphics Graphics systems and interfaces Graphics processors 
* **Abstract**: Memory capacity in GPGPUs is a major challenge for data-intensive applications with their ever increasing memory requirement. To fit a workload into the limited GPU memory space, a programmer needs to manually divide the workload by tiling the working set and perform user-level data migration. To relieve the programmer from this burden, Unified Virtual Memory (UVM) was developed to support on-demand paging and migration, transparent to the user. It further takes care of the memory over-subscription issue by automatically performing page replacement in an oversubscribed GPU memory situation. However, we found that naïve handling of page faults can cause orders of magnitude slowdown in performance. Moreover, we observed that although prefetching of data from CPU to GPU can hide the page fault latency, the difference among various prefetching mechanisms can lead to drastically different performance results. To this end, we performed extensive experiments on GeForceGTX 1080ti GPUs with PCI-e 3.0 16x to discover that there exists an effective prefetch mechanism to enhance locality in GPU memory. However, as the GPU memory is filled to its capacity, such prefetching mechanism quickly proves to be counterproductive due to locality unaware eviction policy. This necessitates the design of new eviction policies that are aware of the hardware prefetcher semantics. We propose two new programmer-agnostic, locality-aware pre-eviction policies which leverage the mechanics of existing hardware prefetcher and thus incur no additional implementation and performance overhead. We demonstrate that combining the proposed tree-based pre-eviction policy with the hardware prefetcher provides an average of 93% and 18.5% performance speed-up compared to LRU based 4KB and 2MB page replacement strategies, respectively. We further examine the memory access pattern of GPU workloads under consideration to analyze the achieved performance speed-up.

---
### Sparse ReRAM engine: joint exploration of activation and weight sparsity in compressed neural networks.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322271
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322271?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Neural networks Special purpose systems Hardware Emerging technologies Memory and dense storage 
* **Abstract**: Exploiting model sparsity to reduce ineffectual computation is a commonly used approach to achieve energy efficiency for DNN inference accelerators. However, due to the tightly coupled crossbar structure, exploiting sparsity for ReRAM-based NN accelerator is a less explored area. Existing architectural studies on ReRAM-based NN accelerators assume that an entire crossbar array can be activated in a single cycle. However, due to inference accuracy considerations, matrix-vector computation must be conducted in a smaller granularity in practice, called Operation Unit (OU). An OU-based architecture creates a new opportunity to exploit DNN sparsity. In this paper, we propose the first practical Sparse ReRAM Engine that exploits both weight and activation sparsity. Our evaluation shows that the proposed method is effective in eliminating ineffectual computation, and delivers significant performance improvement and energy savings.

---
### MnnFast: a fast and scalable system architecture for memory-augmented neural networks.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322214
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322214?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Neural networks Parallel architectures Computing methodologies Machine learning Machine learning approaches Neural networks Parallel computing methodologies Parallel algorithms Hardware Integrated circuits Reconfigurable logic and FPGAs Hardware accelerators Theory of computation Design and analysis of algorithms Parallel algorithms 
* **Abstract**: Memory-augmented neural networks are getting more attention from many researchers as they can make an inference with the previous history stored in memory. Especially, among these memory-augmented neural networks, memory networks are known for their huge reasoning power and capability to learn from a large number of inputs rather than other networks. As the size of input datasets rapidly grows, the necessity of large-scale memory networks continuously arises. Such large-scale memory networks provide excellent reasoning power; however, the current computer infrastructure cannot achieve scalable performance due to its limited system architecture.

---
### TIE: energy-efficient tensor train-based inference engine for deep neural network.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322258
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322258?download=true
* **Key Words**: Computer systems organization Embedded and cyber-physical systems Embedded systems Embedded hardware 
* **Abstract**: In the era of artificial intelligence (AI), deep neural networks (DNNs) have emerged as the most important and powerful AI technique. However, large DNN models are both storage and computation intensive, posing significant challenges for adopting DNNs in resource-constrained scenarios. Thus, model compression becomes a crucial technique to ensure wide deployment of DNNs.

---
### Accelerating distributed reinforcement learning with in-switch computing.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322259
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322259?download=true
* **Key Words**: Computing methodologies Artificial intelligence Distributed artificial intelligence Machine learning Learning paradigms Reinforcement learning Hardware Communication hardware, interfaces and storage Networking hardware Networks Network services In-network processing 
* **Abstract**: Reinforcement learning (RL) has attracted much attention recently, as new and emerging AI-based applications are demanding the capabilities to intelligently react to environment changes. Unlike distributed deep neural network (DNN) training, the distributed RL training has its unique workload characteristics - it generates orders of magnitude more iterations with much smaller sized but more frequent gradient aggregations. More specifically, our study with typical RL algorithms shows that their distributed training is latency critical and that the network communication for gradient aggregation occupies up to 83.2% of the execution time of each training iteration.

---
### Eager pruning: algorithm and architecture support for fast training of deep neural networks.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322263
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322263?download=true
* **Key Words**: 
* **Abstract**: Today's big and fast data and the changing circumstance require fast training of Deep Neural Networks (DNN) in various applications. However, training a DNN with tons of parameters involves intensive computation. Enlightened by the fact that redundancy exists in DNNs and the observation that the ranking of the significance of the weights changes slightly during training, we propose Eager Pruning, which speeds up DNN training by moving pruning to an early stage.

---
### Laconic deep learning inference acceleration.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322255
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322255?download=true
* **Key Words**: 
* **Abstract**: We present a method for transparently identifying ineffectual computations during inference with Deep Learning models. Specifically, by decomposing multiplications down to the bit level, the amount of work needed by multiplications during inference can be potentially reduced by at least 40× across a wide selection of neural networks (8b and 16b). This method produces numerically identical results and does not affect overall accuracy. We present Laconic, a hardware accelerator that implements this approach to boost energy efficiency for inference with Deep Learning Networks. Laconic judiciously gives up some of the work reduction potential to yield a low-cost, simple, and energy efficient design that outperforms other state-of-the-art accelerators: an optimized DaDianNao-like design [13], Eyeriss [15], SCNN [71], Pragmatic [3], and BitFusion [83]. We study 16b, 8b, and 1b/2b fixed-point quantized models.

---
### MicroScope: enabling microarchitectural replay attacks.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322228
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322228?download=true
* **Key Words**: Security and privacy Security in hardware Hardware attacks and countermeasures Side-channel analysis and countermeasures Systems security Operating systems security Trusted computing Software and its engineering Software organization and properties Contextual software domains Operating systems Memory management Virtual memory 
* **Abstract**: The popularity of hardware-based Trusted Execution Environments (TEEs) has recently skyrocketed with the introduction of Intel's Software Guard Extensions (SGX). In SGX, the user process is protected from supervisor software, such as the operating system, through an isolated execution environment called an enclave. Despite the isolation guarantees provided by TEEs, numerous microarchitectural side channel attacks have been demonstrated that bypass their defense mechanisms. But, not all hope is lost for defenders: many modern fine-grain, high-resolution side channels---e.g., execution unit port contention---introduce large amounts of noise, complicating the adversary's task to reliably extract secrets.

---
### SecDir: a secure directory to defeat directory side-channel attacks.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3326635
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3326635?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Multicore architectures Security and privacy Security in hardware Hardware attacks and countermeasures Side-channel analysis and countermeasures 
* **Abstract**: Directories for cache coherence have been recently shown to be vulnerable to conflict-based side-channel attacks. By forcing directory conflicts, an attacker can evict victim directory entries, which in turn trigger the eviction of victim cache lines from private caches. This evidence strongly suggests that directories need to be redesigned for security. The key to a secure directory is to block interference between processes. Sadly, in an environment with many cores, this is hard or expensive to do.

---
### Secure TLBs.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322238
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322238?download=true
* **Key Words**: Computer systems organization Architectures Serial architectures Reduced instruction set computing Embedded and cyber-physical systems Embedded systems Embedded hardware Security and privacy Security in hardware Hardware attacks and countermeasures Side-channel analysis and countermeasures 
* **Abstract**: This paper focuses on a new attack vector in modern processors: the timing-based side and covert channel attacks due to the Translation Look-aside Buffers (TLBs). This paper first presents a novel three-step modeling approach that is used to exhaustively enumerate all possible TLB timing-based vulnerabilities. Building on the three-step model, this paper then shows how to automatically generate micro security benchmarks that test for the TLB vulnerabilities. After showing the insecurity of standard TLBs, two new secure TLB designs are presented: a Static-Partition (SP) TLB and a Random-Fill (RF) TLB. The new secure TLBs are evaluated using the Rocket Core implementation of the RISC-V processor architecture enhanced with the two new designs. The three-step model and the security benchmarks are used to analyze the security of the new designs in simulation. Based on the analysis, the proposed secure TLBs can defend not only against the previously publicized attacks but also against other new timing-based attacks in TLBs found using the new three-step model. The performance overhead is evaluated on an FPGA-based setup, and, for example, shows that the RF TLB has less than 10% overhead while defending all the attacks.

---
### New attacks and defense for encrypted-address cache.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322246
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322246?download=true
* **Key Words**: 
* **Abstract**: Conflict-based cache attacks can allow an adversary to infer the access pattern of a co-running application by orchestrating evictions via cache conflicts. Such attacks can be mitigated by randomizing the location of the lines in the cache. Our recent proposal, CEASER, makes cache randomization practical by accessing the cache using an encrypted address and periodically changing the encryption key. CEASER was analyzed with the state-of-the-art algorithm on forming eviction sets, and the analysis showed that CEASER with a Remap-Rate of 1% is sufficient to tolerate years of attack.

---
### InvisiPage: oblivious demand paging for secure enclaves.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322265
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322265?download=true
* **Key Words**: Security and privacy Security in hardware Hardware security implementation Hardware-based security protocols 
* **Abstract**: State-of-art secure processors like Intel SGX remain susceptible to leaking page-level address trace of an application via the page fault channel in which a malicious OS induces spurious page faults and deduces application's secrets from it. Prior works which fix this vulnerability do not provision for OS demand paging to be oblivious. In this work, we present InvisiPage which obfuscates page fault channel while simultaneously making OS demand paging oblivious. To do so, InvisiPage first carefully distributes page management actions between the application and the OS. Second, InvisiPage secures application's page management interactions with the OS using a novel construct which is derived from Oblivious RAM (ORAM) but is customized for page management. Finally, we lower overheads of our approach by reducing page management interactions with the OS via a novel memory partition. For a suite of cloud applications which process sensitive data we show that page fault channel can be tackled while enabling oblivious demand paging at low overheads.

---
### TWiCe: preventing row-hammering by exploiting time window counters.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322232
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322232?download=true
* **Key Words**: Hardware Integrated circuits Semiconductor memory Dynamic memory 
* **Abstract**: Computer systems using DRAM are exposed to row-hammer (RH) attacks, which can flip data in a DRAM row without directly accessing a row but by frequently activating its adjacent ones. There have been a number of proposals to prevent RH, but they either incur large area overhead, suffer from noticeable performance drop on adversarial memory access patterns, or provide probabilistic protection with no capability to detect attacks.

---
### Duality cache for data parallel acceleration.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322257
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322257?download=true
* **Key Words**: 
* **Abstract**: Duality Cache is an in-cache computation architecture that enables general purpose data parallel applications to run on caches. This paper presents a holistic approach of building Duality Cache system stack with techniques of performing in-cache floating point arithmetic and transcendental functions, enabling a data-parallel execution model, designing a compiler that accepts existing CUDA programs, and providing flexibility in adopting for various workload characteristics.

---
### Adaptive memory-side last-level GPU caching.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322235
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322235?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Single instruction, multiple data 
* **Abstract**: Emerging GPU applications exhibit increasingly high computation demands which has led GPU manufacturers to build GPUs with an increasingly large number of streaming multiprocessors (SMs). Providing data to the SMs at high bandwidth puts significant pressure on the memory hierarchy and the Network-on-Chip (NoC). Current GPUs typically partition the memory-side last-level cache (LLC) in equally-sized slices that are shared by all SMs. Although a shared LLC typically results in a lower miss rate, we find that for workloads with high degrees of data sharing across SMs, a private LLC leads to a significant performance advantage because of increased bandwidth to replicated cache lines across different LLC slices.

---
### SCU: a GPU stream compaction unit for graph processing.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322254
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322254?download=true
* **Key Words**: Computing methodologies Computer graphics Graphics systems and interfaces Graphics processors Hardware Integrated circuits Reconfigurable logic and FPGAs Hardware accelerators 
* **Abstract**: Graph processing algorithms are key in many emerging applications in areas such as machine learning and data analytics. Although the processing of large scale graphs exhibits a high degree of parallelism, the memory access pattern tend to be highly irregular, leading to poor GPGPU efficiency due to memory divergence. To ameliorate this issue, GPGPU applications perform a stream compaction operation each iteration of the algorithm to extract the subset of active nodes/edges, so subsequent steps work on compacted dataset.

---
### Filter caching for free: the untapped potential of the store-buffer.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322269
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322269?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Multicore architectures Serial architectures Pipeline computing Superscalar architectures 
* **Abstract**: Modern processors contain store-buffers to allow stores to retire under a miss, thus hiding store-miss latency. The store-buffer needs to be large (for performance) and searched on every load (for correctness), thereby making it a costly structure in both area and energy. Yet on every load, the store-buffer is probed in parallel with the L1 and TLB, with no concern for the store-buffer's intrinsic hit rate or whether a store-buffer hit can be predicted to save energy by disabling the L1 and TLB probes.

---
### Efficient metadata management for irregular data prefetching.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322225
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322225?download=true
* **Key Words**: Hardware Integrated circuits Semiconductor memory Dynamic memory 
* **Abstract**: Temporal prefetchers have the potential to prefetch arbitrary memory access patterns, but they require large amounts of metadata that must typically be stored in DRAM. In 2013, the Irregular Stream Buffer (ISB), showed how this metadata could be cached on chip and managed implicitly by synchronizing its contents with that of the TLB. This paper reveals the inefficiency of that approach and presents a new metadata management scheme that uses a simple metadata prefetcher to feed the metadata cache. The result is the Managed ISB (MISB), a temporal prefetcher that significantly advances the state-of-the-art in terms of both traffic overhead and IPC.

---
### AsmDB: understanding and mitigating front-end stalls in warehouse-scale computers.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322234
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322234?download=true
* **Key Words**: Computer systems organization Dependable and fault-tolerant systems and networks General and reference Cross-computing tools and techniques Performance Social and professional topics Professional topics Computing profession Testing, certification and licensing 
* **Abstract**: The large instruction working sets of private and public cloud workloads lead to frequent instruction cache misses and costs in the millions of dollars. While prior work has identified the growing importance of this problem, to date, there has been little analysis of where the misses come from, and what the opportunities are to improve them. To address this challenge, this paper makes three contributions. First, we present the design and deployment of a new, always-on, fleet-wide monitoring system, AsmDB, that tracks front-end bottlenecks. AsmDB uses hardware support to collect bursty execution traces, fleet-wide temporal and spatial sampling, and sophisticated offline post-processing to construct full-program dynamic control-flow graphs. Second, based on a longitudinal analysis of AsmDB data from real-world online services, we present two detailed insights on the sources of front-end stalls: (1) cold code that is brought in along with hot code leads to significant cache fragmentation and a corresponding large number of instruction cache misses; (2) distant branches and calls that are not amenable to traditional cache locality or next-line prefetching strategies account for a large fraction of cache misses. Third, we prototype two optimizations that target these insights. For misses caused by fragmentation, we focus on memcmp, one of the hottest functions contributing to cache misses, and show how fine-grained layout optimizations lead to significant benefits. For misses at the targets of distant jumps, we propose new hardware support for software code prefetching and prototype a new feedback-directed compiler optimization that combines static program flow analysis with dynamic miss profiles to demonstrate significant benefits for several large warehouse-scale workloads. Improving upon prior work, our proposal avoids invasive hardware modifications by prefetching via software in an efficient and scalable way. Simulation results show that such an approach can eliminate up to 96% of instruction cache misses with negligible overheads.

---
### Fine-grained warm water cooling for improving datacenter economy.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322236
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322236?download=true
* **Key Words**: Computer systems organization Architectures Hardware Power and energy Power estimation and optimization Enterprise level and data centers power issues Thermal issues 
* **Abstract**: Driven by the increasing power consumption of datacenters, the industry is focusing more on water cooling for improving the energy efficiency. Using warm water to cool servers has been considered as an efficient method to reduce the cooling energy. However, warm water cooling may lead to the risk of cooling failure and its energy efficiency suffers from the thermal imbalance among servers, due to the lack of fine-grained cooling control. In this paper, we propose a hybrid cooling architecture design that incorporates thermoelectric cooler into the water cooling system, to deal with cooling mismatching in a fine-grained manner. We exploit the warm water cooling strategy and design an adaptive cooling control framework according to workload variations, to make water cooling system more economical for datacenters. We evaluate the hybrid water cooling design based on a real hardware prototype and cluster traces from Google and Alibaba. Compared with conventional water cooling system, our hybrid water cooling system can reduce the energy consumption by 58.72%~78.43% to handle the cooling mismatching.

---
### DeepAttest: an end-to-end attestation framework for deep neural networks.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322251
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322251?download=true
* **Key Words**: Computing methodologies Machine learning Security and privacy Security in hardware Security services Authentication 
* **Abstract**: Emerging hardware architectures for Deep Neural Networks (DNNs) are being commercialized and considered as the hardware-level Intellectual Property (IP) of the device providers. However, these intelligent devices might be abused and such vulnerability has not been identified. The unregulated usage of intelligent platforms and the lack of hardware-bounded IP protection impair the commercial advantage of the device provider and prohibit reliable technology transfer. Our goal is to design a systematic methodology that provides hardware-level IP protection and usage control for DNN applications on various platforms. To address the IP concern, we present DeepAttest, the first on-device DNN attestation method that certifies the legitimacy of the DNN program mapped to the device. DeepAttest works by designing a device-specific fingerprint which is encoded in the weights of the DNN deployed on the target platform. The embedded fingerprint (FP) is later extracted with the support of the Trusted Execution Environment (TEE). The existence of the pre-defined FP is used as the attestation criterion to determine whether the queried DNN is authenticated. Our attestation framework ensures that only authorized DNN programs yield the matching FP and are allowed for inference on the target device. DeepAttest provisions the device provider with a practical solution to limit the application usage of her manufactured hardware and prevents unauthorized or tampered DNNs from execution.

---
### TPShare: a time-space sharing scheduling abstraction for shared cloud via vertical labels.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3326634
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3326634?download=true
* **Key Words**: Computer systems organization Architectures Distributed architectures Cloud computing 
* **Abstract**: Current shared cloud operating systems (cloud OS) such as Mesos and YARN are based on the "de facto" two-horizontal-layer cloud platform architecture, which decouples cloud application frameworks (e.g., Apache Spark) from the underlying resource management infrastructure. Each layer normally has its own task or resource allocation scheduler, based on either time-sharing or space-sharing. As such, the schedulers in different layers are unavoidably disconnected, --- not aware of each other, which highly likely leads to resource (e.g.,CPU) wastes. Moreover, the tail latency may even be harmed due to the performance interference on shared resources.

---
### SoftSKU: optimizing server architectures for microservice diversity @scale.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322227
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322227?download=true
* **Key Words**: Computer systems organization Architectures Distributed architectures Cloud computing 
* **Abstract**: The variety and complexity of microservices in warehouse-scale data centers has grown precipitously over the last few years to support a growing user base and an evolving product portfolio. Despite accelerating microservice diversity, there is a strong requirement to limit diversity in underlying server hardware to maintain hardware resource fungibility, preserve procurement economies of scale, and curb qualification/test overheads. As such, there is an urgent need for strategies that enable limited server CPU architectures (a.k.a "SKUs") to provide performance and energy efficiency over diverse microservices. To this end, we first undertake a comprehensive characterization of the top seven microservices that run on the compute-optimized data center fleet at Facebook.

---
### Full-stack, real-system quantum computer studies: architectural comparisons and design insights.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322273
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322273?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Quantum computing Software and its engineering Software notations and tools Compilers 
* **Abstract**: In recent years, Quantum Computing (QC) has progressed to the point where small working prototypes are available for use. Termed Noisy Intermediate-Scale Quantum (NISQ) computers, these prototypes are too small for large benchmarks or even for Quantum Error Correction (QEC), but they do have sufficient resources to run small benchmarks, particularly if compiled with optimizations to make use of scarce qubits and limited operation counts and coherence times. QC has not yet, however, settled on a particular preferred device implementation technology, and indeed different NISQ prototypes implement qubits with very different physical approaches and therefore widely-varying device and machine characteristics.

---
### Statistical assertions for validating patterns and finding bugs in quantum programs.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322213
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322213?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Quantum computing Hardware Emerging technologies Quantum technologies Quantum computation Software and its engineering Software creation and management Software verification and validation Software defect analysis Software testing and debugging Software notations and tools General programming languages Language features Patterns Theory of computation Semantics and reasoning Program reasoning Assertions 
* **Abstract**: In support of the growing interest in quantum computing experimentation, programmers need new tools to write quantum algorithms as program code. Compared to debugging classical programs, debugging quantum programs is difficult because programmers have limited ability to probe the internal states of quantum programs; those states are difficult to interpret even when observations exist; and programmers do not yet have guidelines for what to check for when building quantum programs. In this work, we present quantum program assertions based on statistical tests on classical observations. These allow programmers to decide if a quantum program state matches its expected value in one of classical, superposition, or entangled types of states. We extend an existing quantum programming language with the ability to specify quantum assertions, which our tool then checks in a quantum program simulator. We use these assertions to debug three benchmark quantum programs in factoring, search, and chemistry. We share what types of bugs are possible, and lay out a strategy for using quantum programming patterns to place assertions and prevent bugs.

---
### Asymptotic improvements to quantum circuits via qutrits.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322253
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322253?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Quantum computing 
* **Abstract**: Quantum computation is traditionally expressed in terms of quantum bits, or qubits. In this work, we instead consider three-level qutrits. Past work with qutrits has demonstrated only constant factor improvements, owing to the log2(3) binary-to-ternary compression factor. We present a novel technique using qutrits to achieve a logarithmic depth (runtime) decomposition of the Generalized Toffoli gate using no ancilla-a significant improvement over linear depth for the best qubit-only equivalent. Our circuit construction also features a 70x improvement in two-qudit gate count over the qubit-only equivalent decomposition. This results in circuit cost reductions for important algorithms like quantum neurons and Grover search. We develop an open-source circuit simulator for qutrits, along with realistic near-term noise models which account for the cost of operating qutrits. Simulation results for these noise models indicate over 90% mean reliability (fidelity) for our circuit construction, versus under 30% for the qubit-only baseline. These results suggest that qutrits offer a promising path towards scaling quantum computation.

---
### A stochastic-computing based deep learning framework using adiabatic quantum-flux-parametron superconducting technology.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322270
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322270?download=true
* **Key Words**: 
* **Abstract**: The Adiabatic Quantum-Flux-Parametron (AQFP) superconducting technology has been recently developed, which achieves the highest energy efficiency among superconducting logic families, potentially 104--105 gain compared with state-of-the-art CMOS. In 2016, the successful fabrication and testing of AQFP-based circuits with the scale of 83,000 JJs have demonstrated the scalability and potential of implementing large-scale systems using AQFP. As a result, it will be promising for AQFP in high-performance computing and deep space applications, with Deep Neural Network (DNN) inference acceleration as an important example.

---
### A quantum computational compiler and design tool for technology-specific targets.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322262
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322262?download=true
* **Key Words**: Hardware Emerging technologies Quantum technologies Quantum computation 
* **Abstract**: Quantum computing, once just a theoretical field, is quickly advancing as physical quantum technology increases in size, capability, and reliability. In order to fully harness the power of a general quantum computer or an application-specific device, compilers and tools must be developed that optimize specifications and map them to a realization on a specific architecture. In this work, a technique and prototype tool for synthesizing algorithms into a quantum computer is described and evaluated. Most recently reported methods produce technologically-independent reversible cascades comprised of a functionally complete set of operators with no regard to actual technologically-dependent cell libraries or constraints due to a device's pre-configured interconnectivity. In contrast, our prototype tool synthesizes algorithms into technologically-dependent specifications that consist of a set of primitives and connectivity constraints present in the computer architecture. The tool performs optimizations based on actual architectural constraints, and a high-quality technology-dependent synthesized result is achieved through the use of optimizing cost functions derived from real hardware and architecture parameters. Additionally, another important aspect of our tool is the incorporation of internal formal equivalence checking that ensures the initially specified algorithm is functionally equivalent to the optimized, technologically-mapped output. Experimental results are provided that target the IBM Q family of quantum computers.

---
### IntelliNoC: a holistic design framework for energy-efficient and reliable on-chip communication for manycores.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322274
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322274?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Interconnection architectures Multicore architectures Hardware Very large scale integration design Design reuse and communication-based design Network on chip Networks Network performance evaluation Network performance analysis Theory of computation Theory and algorithms for application domains Machine learning theory Reinforcement learning 
* **Abstract**: As technology scales, Network-on-Chips (NoCs), currently being used for on-chip communication in manycore architectures, face several problems including high network latency, excessive power consumption, and low reliability. Simultaneously addressing these problems is proving to be difficult due to the explosion of the design space and the complexity of handling many trade-offs. In this paper, we propose IntelliNoC, an intelligent NoC design framework which introduces architectural innovations and uses reinforcement learning to manage the design complexity and simultaneously optimize performance, energy-efficiency, and reliability in a holistic manner. IntelliNoC integrates three NoC architectural techniques: (1) multifunction adaptive channels (MFACs) to improve energy-efficiency; (2) adaptive error detection/correction and re-transmission control to enhance reliability; and (3) a stress-relaxing bypass feature which dynamically powers off NoC components to prevent overheating and fatigue. To handle the complex dynamic interactions induced by these techniques, we train a dynamic control policy using Q-learning, with the goal of providing improved fault-tolerance and performance while reducing power consumption and area overhead. Simulation using PARSEC benchmarks shows that our proposed IntelliNoC design improves energy-efficiency by 67% and mean-time-to-failure (MTTF) by 77%, and decreases end-to-end packet latency by 32% and area requirements by 25% over baseline NoC architecture.

---
### HALO: accelerating flow classification for scalable packet processing in NFV.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322272
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322272?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Multicore architectures Hardware Communication hardware, interfaces and storage Networking hardware 
* **Abstract**: Network Function Virtualization (NFV) has become the new standard in the cloud platform, as it provides the flexibility and agility for deploying various network services on general-purpose servers. However, it still suffers from sub-optimal performance in software packet processing. Our characterization study of virtual switches shows that the flow classification is the major bottleneck that limits the throughput of the packet processing in NFV, even though a large portion of the classification rules can be cached in the last level cache (LLC) in modern servers.

---
### Scalable interconnects for reconfigurable spatial architectures.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322249
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322249?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Interconnection architectures Hardware Integrated circuits Reconfigurable logic and FPGAs Hardware accelerators 
* **Abstract**: Recent years have seen the increased adoption of Coarse-Grained Reconfigurable Architectures (CGRAs) as flexible, energy-efficient compute accelerators. Obtaining performance using spatial architectures while supporting diverse applications requires a flexible, high-bandwidth interconnect. Because modern CGRAs support vector units with wide datapaths, designing an interconnect that balances dynamism, communication granularity, and programmability is a challenging task.

---
### CoNDA: efficient cache coherence support for near-data accelerators.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322266
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322266?download=true
* **Key Words**: 
* **Abstract**: Specialized on-chip accelerators are widely used to improve the energy efficiency of computing systems. Recent advances in memory technology have enabled near-data accelerators (NDAs), which reside off-chip close to main memory and can yield further benefits than on-chip accelerators. However, enforcing coherence with the rest of the system, which is already a major challenge for accelerators, becomes more difficult for NDAs. This is because (1) the cost of communication between NDAs and CPUs is high, and (2) NDA applications generate a lot of off-chip data movement. As a result, as we show in this work, existing coherence mechanisms eliminate most of the benefits of NDAs. We extensively analyze these mechanisms, and observe that (1) the majority of off-chip coherence traffic is unnecessary, and (2) much of the off-chip traffic can be eliminated if a coherence mechanism has insight into the memory accesses performed by the NDA.

---
### Designing vertical processors in monolithic 3D.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322233
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322233?download=true
* **Key Words**: Hardware Electronic design automation Physical design (EDA) Partitioning and floorplanning Emerging technologies Analysis and design of emerging devices and systems Emerging architectures Integrated circuits 3D integrated circuits Power and energy Power estimation and optimization Chip-level power issues Very large scale integration design VLSI packaging Die and wafer stacking 
* **Abstract**: A processor laid out vertically in stacked layers can benefit from reduced wire delays, low energy consumption, and a small footprint. Such a design can be enabled by Monolithic 3D (M3D), a technology that provides short wire lengths, good thermal properties, and high integration. In current M3D technology, due to manufacturing constraints, the layers in the stack are asymmetric: the bottom-most one has a relatively higher performance.

---
### Time squeezing for tiny devices.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322268
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322268?download=true
* **Key Words**: Computer systems organization Embedded and cyber-physical systems Embedded systems Software and its engineering Software notations and tools Compilers 
* **Abstract**: Dynamic timing slack has emerged as a compelling opportunity for eliminating inefficiency in ultra-low power embedded systems. This slack arises when all the signals have propagated through logic paths well in advance of the clock signal. When it is properly identified, the system can exploit this unused cycle time for energy savings. In this paper, we describe compiler and architecture co-design that opens new opportunities for timing slack that are otherwise impossible. Through cross-layer optimization, we introduce novel mechanisms in the hardware and in the compiler that work together to improve the benefit of circuit-level timing speculation by effectively squeezing time during execution. This approach is particularly well-suited to tiny embedded devices. Our evaluation on a gate-level model of a complete processor shows that our co-design saves (on average) 40.5% of the original energy consumption (additional 16.5% compared to the existing clock scheduling technique) across 13 workloads while retaining transparency to developers.

---
### XPC: architectural support for secure and efficient cross process call.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322218
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322218?download=true
* **Key Words**: Computer systems organization Architectures Software and its engineering Software organization and properties Contextual software domains Operating systems 
* **Abstract**: Microkernel has many intriguing features like security, fault-tolerance, modularity and customizability, which recently stimulate a resurgent interest in both academia and industry (including seL4, QNX and Google's Fuchsia OS). However, IPC (inter-process communication), which is known as the Achilles' Heel of microkernels, is still the major factor for the overall (poor) OS performance. Besides, IPC also plays a vital role in monolithic kernels like Android Linux, as mobile applications frequently communicate with plenty of user-level services through IPC. Previous software optimizations of IPC usually cannot bypass the kernel which is responsible for domain switching and message copying/remapping; hardware solutions like tagged memory or capability replace page tables for isolation, but usually require non-trivial modification to existing software stack to adapt the new hardware primitives. In this paper, we propose a hardware-assisted OS primitive, XPC (Cross Process Call), for fast and secure synchronous IPC. XPC enables direct switch between IPC caller and callee without trapping into the kernel, and supports message passing across multiple processes through the invocation chain without copying. The primitive is compatible with the traditional address space based isolation mechanism and can be easily integrated into existing microkernels and monolithic kernels. We have implemented a prototype of XPC based on a Rocket RISC-V core with FPGA boards and ported two microkernel implementations, seL4 and Zircon, and one monolithic kernel implementation, Android Binder, for evaluation. We also implement XPC on GEM5 simulator to validate the generality. The result shows that XPC can reduce IPC call latency from 664 to 21 cycles, up to 54.2x improvement on Android Binder, and improve the performance of real-world applications on microkernels by 1.6x on Sqlite3 and 10x on an HTTP server with minimal hardware resource cost.

---
### AxMemo: hardware-compiler co-design for approximate code memoization.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322215
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322215?download=true
* **Key Words**: Computer systems organization Embedded and cyber-physical systems Embedded systems Embedded hardware 
* **Abstract**: Historically, continuous improvements in general-purpose processors have fueled the economic success and growth of the IT industry. However, the diminishing benefits from transistor scaling and conventional optimization techniques necessitates moving beyond common practices. Approximate computing is one such unconventional technique that has shown promise in pushing the boundaries of general-purpose processing. This paper sets out to employ approximation for processors that are commonly used in cyber-physical domains and may become building blocks of Internet of Things. To this end, we propose AxMemo to exploit the computation redundancy that stems from data similarity in the inputs of code blocks. Such input behavior is prevalent in cyber-physical systems as they deal with real-world data that naturally harbors redundancy. Therefore, in contrast to existing memoization techniques that replace costly floating-point arithmetic operations with limited number of inputs, AxMemo focuses on memoizing blocks of code with potentially many inputs. As such, AxMemo aims to replace long sequences of instructions with a few hash and lookup operations. By reducing the number of dynamic instructions, AxMemo alleviates the von Neumann and execution overheads of passing instructions through the processor pipeline altogether. The challenge AxMemo facing is to provide low-cost hashing mechanisms that can generate rather unique signature for each multi-input combination. To address this challenge, we develop a novel use of Cyclic Redundancy Checking (CRC) to hash the inputs. To increase lookup table hit rate, AxMemo employs a two-level memoization lookup, which utilizes small dedicated SRAM and spare storage in the last level cache. These solutions enable AxMemo to efficiently memoize relatively large code regions with variable input sizes and types using the same underlying hardware. Our experiment shows that AxMemo offers 2.64× speedup and 2.58 × energy reduction with mere 0.2% of quality loss averaged across ten benchmarks. These benefits come with an area overhead of just 2.1%.

---
### Translation ranger: operating system support for contiguity-aware TLBs.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322223
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322223?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Heterogeneous (hybrid) systems Software and its engineering Software organization and properties Contextual software domains Operating systems Memory management Virtual memory 
* **Abstract**: Virtual memory (VM) eases programming effort but can suffer from high address translation overheads. Architects have traditionally coped by increasing Translation Lookaside Buffer (TLB) capacity; this approach, however, requires considerable hardware resources. One promising alternative is to rely on software-generated translation contiguity to compress page translation encodings within the TLB. To enable this, operating systems (OSes) have to assign spatially-adjacent groups of physical frames to contiguous groups of virtual pages, as doing so allows compression or coalescing of these contiguous translations in hardware. Unfortunately, modern OSes do not currently guarantee translation contiguity in many real-world scenarios; as systems remain online for long periods of time, their memory can and does become fragmented.

---
### Bouncer: static program analysis in hardware.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322256
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322256?download=true
* **Key Words**: 
* **Abstract**: When discussing safety and security for embedded systems, we typically divide the world into software checks (which are either static or dynamic) or hardware checks (which are dynamic). As others have pointed out, hardware checks offer more than just efficiency. They are intrinsic to the device's functionality and thus are live from power-up; they require little to no dependency on other software functioning correctly, and due to the fact they are wired directly into the operation of the system, are difficult or impossible to bypass. We explore an experimental new embedded system that uses special-purpose hardware for static analysis that prevents all program binaries with memory errors, invalid control flow, and several other undesirable properties from ever being loaded onto the device. Static analysis often requires whole-binary-level, rather than instruction-level, examination. We show that a carefully constructed hardware state machine, using available scratch-pad memory, is capable of efficiently checking functional binaries in a streaming and verifiably non-bypassable way directly in hardware as they are loaded into the embedded program store. The resulting system is surprisingly small (taking no more than .0079 mm2), efficient (capable of checking binaries at an average throughput of around 60 cycles per instruction), and yet guarantees execution free from many of the fragile behaviors that result in security and safety concerns. We believe this is the first time any static analysis has been implemented at the hardware level and opens the door to more complex hardware-checked properties.

---
### Efficient invisible speculative execution through selective delay and value prediction.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322216
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322216?download=true
* **Key Words**: Security and privacy Security in hardware Hardware attacks and countermeasures Side-channel analysis and countermeasures 
* **Abstract**: Speculative execution, the base on which modern high-performance general-purpose CPUs are built on, has recently been shown to enable a slew of security attacks. All these attacks are centered around a common set of behaviors: During speculative execution, the architectural state of the system is kept unmodified, until the speculation can be verified. In the event that a misspeculation occurs, then anything that can affect the architectural state is reverted (squashed) and re-executed correctly. However, the same is not true for the microarchitectural state. Normally invisible to the user, changes to the microarchitectural state can be observed through various side-channels, with timing differences caused by the memory hierarchy being one of the most common and easy to exploit. The speculative side-channels can then be exploited to perform attacks that can bypass software and hardware checks in order to leak information. These attacks, out of which the most infamous are perhaps Spectre and Meltdown, have led to a frantic search for solutions.

---
### Stream-based memory access specialization for general purpose processors.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322229
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322229?download=true
* **Key Words**: Computer systems organization Architectures Other architectures Heterogeneous (hybrid) systems 
* **Abstract**: Because of severe limitations in technology scaling, architects have innovated in specializing general purpose processors for computation primitives (e.g. vector instructions, loop accelerators). The general principle is exposing rich semantics to the ISA. An opportunity to explore is whether richer semantics of memory access patterns could also be used to improve the efficiency of memory and communication. Two important open questions are how to convey higher level memory information and how to take advantage of this information in hardware.

---
### Using SMT to accelerate nested virtualization.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322261
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322261?download=true
* **Key Words**: Security and privacy Systems security Operating systems security Virtualization and security Software and its engineering Software organization and properties Contextual software domains Software infrastructure Virtual machines 
* **Abstract**: IaaS datacenters offer virtual machines (VMs) to their clients, who in turn sometimes deploy their own virtualized environments, thereby running a VM inside a VM. This is known as nested virtualization.

---
### Master of none acceleration: a comparison of accelerator architectures for analytical query processing.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322220
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322220?download=true
* **Key Words**: Computer systems organization Architectures Parallel architectures Systolic arrays Information systems Data management systems Database management system engines Database query processing 
* **Abstract**: Hardware accelerators are one promising solution to contend with the end of Dennard scaling and the slowdown of Moore's law. For mature workloads that are regular and have high compute per byte, hardening an application into one or more hardware modules is a standard approach. However, for some applications, we find that a programmable homogeneous architecture is preferable.

---
### Cryogenic computer architecture modeling with memory-side case studies.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322219
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322219?download=true
* **Key Words**: Hardware Electronic design automation Modeling and parameter extraction Emerging technologies Analysis and design of emerging devices and systems Emerging architectures Memory and dense storage Integrated circuits Digital switches Transistors Semiconductor memory Dynamic memory Power and energy Power estimation and optimization Chip-level power issues Enterprise level and data centers power issues Thermal issues Temperature simulation and estimation 
* **Abstract**: Modern computer architectures suffer from lack of architectural innovations, mainly due to the power wall and the memory wall. That is, architectural innovations become infeasible because they can prohibitively increase power consumption and their performance impacts are eventually bounded by slow memory accesses. To address the challenges, making computer systems run at ultra-low temperatures (or cryogenic computer systems) has emerged as a highly promising solution as both power consumption and wire resistivity are expected to significantly reduce at ultra-low temperatures. However, cryogenic computers have not been yet realized as computer architects do not fully understand the behaviors of existing computer systems and their cost effectiveness at such ultra-low temperatures.

---
### Cambricon-F: machine learning computers with fractal von neumann architecture.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322226
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322226?download=true
* **Key Words**: Computer systems organization Dependable and fault-tolerant systems and networks Networks Network performance evaluation 
* **Abstract**: Machine learning techniques are pervasive tools for emerging commercial applications and many dedicated machine learning computers on different scales have been deployed in embedded devices, servers, and data centers. Currently, most machine learning computer architectures still focus on optimizing performance and energy efficiency instead of programming productivity. However, with the fast development in silicon technology, programming productivity, including programming itself and software stack development, becomes the vital reason instead of performance and power efficiency that hinders the application of machine learning computers.

---
### FloatPIM: in-memory acceleration of deep neural network training with high precision.
* **Publisher**: ACM
* **DOI**: https://doi.org/10.1145/3307650.3322237
* **PDF**: https://dl.acm.org/doi/pdf/10.1145/3307650.3322237?download=true
* **Key Words**: Computer systems organization Architectures Computing methodologies Machine learning Hardware Emerging technologies 
* **Abstract**: Processing In-Memory (PIM) has shown a great potential to accelerate inference tasks of Convolutional Neural Network (CNN). However, existing PIM architectures do not support high precision computation, e.g., in floating point precision, which is essential for training accurate CNN models. In addition, most of the existing PIM approaches require analog/mixed-signal circuits, which do not scale, exploiting insufficiently reliable multi-bit Non-Volatile Memory (NVM). In this paper, we propose FloatPIM, a fully-digital scalable PIM architecture that accelerates CNN in both training and testing phases. FloatPIM natively supports floating-point representation, thus enabling accurate CNN training. FloatPIM also enables fast communication between neighboring memory blocks to reduce internal data movement of the PIM architecture. We evaluate the efficiency of FloatPIM on ImageNet dataset using popular large-scale neural networks. Our evaluation shows that FloatPIM supporting floating point precision can achieve up to 5.1% higher classification accuracy as compared to existing PIM architectures with limited fixed-point precision. FloatPIM training is on average 303.2× and 48.6× (4.3× and 15.8×) faster and more energy efficient as compared to GTX 1080 GPU (PipeLayer [1] PIM accelerator). For testing, FloatPIM also provides 324.8× and 297.9× (6.3× and 21.6×) speedup and energy efficiency as compared to GPU (ISAAC [2] PIM accelerator) respectively.
